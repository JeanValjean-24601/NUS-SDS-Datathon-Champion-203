{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas \n",
    "#%pip install matplotlib\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME\n",
    "#%pip install seaborn \n",
    "#%pip install -U scikit-learn\n",
    "#%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .csv file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "filepath = \"./data/catA_train.csv\" \n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LATITUDE                               0\n",
       "LONGITUDE                              0\n",
       "AccountID                              0\n",
       "Company                                0\n",
       "SIC Code                               0\n",
       "Industry                               0\n",
       "8-Digit SIC Code                       0\n",
       "8-Digit SIC Description                0\n",
       "Year Found                             0\n",
       "Entity Type                            0\n",
       "Parent Company                         0\n",
       "Parent Country                         0\n",
       "Ownership Type                         0\n",
       "Company Description                    0\n",
       "Company Status (Active/Inactive)       0\n",
       "Employees (Single Site)                0\n",
       "Employees (Domestic Ultimate Total)    0\n",
       "Employees (Global Ultimate Total)      0\n",
       "Sales (Domestic Ultimate Total USD)    0\n",
       "Sales (Global Ultimate Total USD)      0\n",
       "Global Ultimate Company                0\n",
       "Global Ultimate Country                0\n",
       "Domestic Ultimate Company              0\n",
       "Is Domestic Ultimate                   0\n",
       "Is Global Ultimate                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###...code...###\n",
    "import os \n",
    "os.chdir('C:/Users/alber/OneDrive/Documents')\n",
    "filepath = 'C:/Users/alber/Downloads/catA_train.csv'\n",
    "\n",
    "data = pd.read_csv(filepath)\n",
    "threshold = 0.5  # threshold to remove columns\n",
    "columns_to_drop = data.columns[data.isnull().mean() > threshold]\n",
    "data_cleaned = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Impute missing values for remaining columns\n",
    "# For numerical columns, use mean  or median\n",
    "# For categorical columns, use mode\n",
    "for column in data_cleaned.columns:\n",
    "    if data_cleaned[column].dtype == 'object':\n",
    "        data_cleaned[column].fillna(data_cleaned[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        data_cleaned[column].fillna(data_cleaned[column].median(), inplace=True)\n",
    "\n",
    "data.isna().sum()\n",
    "data_cleaned.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alber\\Downloads\\NUS_DATATHON_CHAMPION_204.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alber/Downloads/NUS_DATATHON_CHAMPION_204.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Preprocess the data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alber/Downloads/NUS_DATATHON_CHAMPION_204.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Handle missing values, remove or impute\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alber/Downloads/NUS_DATATHON_CHAMPION_204.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Assuming missing values are handled as per previous discussion\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alber/Downloads/NUS_DATATHON_CHAMPION_204.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alber/Downloads/NUS_DATATHON_CHAMPION_204.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Encoding categorical variables\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alber/Downloads/NUS_DATATHON_CHAMPION_204.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m categorical_columns \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alber/Downloads/NUS_DATATHON_CHAMPION_204.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m one_hot_encoder \u001b[39m=\u001b[39m OneHotEncoder(sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alber/Downloads/NUS_DATATHON_CHAMPION_204.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m encoded_categorical \u001b[39m=\u001b[39m one_hot_encoder\u001b[39m.\u001b[39mfit_transform(data[categorical_columns])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alber/Downloads/NUS_DATATHON_CHAMPION_204.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m encoded_categorical \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(encoded_categorical, columns\u001b[39m=\u001b[39mone_hot_encoder\u001b[39m.\u001b[39mget_feature_names_out(categorical_columns))\n",
      "\u001b[1;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "import os \n",
    "os.chdir('C:/Users/alber/OneDrive/Documents')\n",
    "\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "# Preprocess the data\n",
    "# Handle missing values, remove or impute\n",
    "# Assuming missing values are handled as per previous discussion\n",
    "\n",
    "# Encoding categorical variables\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_categorical = one_hot_encoder.fit_transform(data[categorical_columns])\n",
    "encoded_categorical = pd.DataFrame(encoded_categorical, columns=one_hot_encoder.get_feature_names_out(categorical_columns))\n",
    "data = data.drop(columns=categorical_columns).join(encoded_categorical)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data.drop(columns=['Sales (Global Ultimate Total USD)']))  # Adjust the column name\n",
    "scaled_features = pd.DataFrame(scaled_features, columns=data.columns.difference(['Sales (Global Ultimate Total USD)']))\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X = scaled_features\n",
    "y = data['Sales (Global Ultimate Total USD)']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the Neural Network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1))  # Single unit for regression output\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# You might also want to calculate other metrics such as MAE or R^2 based on your needs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "\n",
    "    result = [] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_csv(filepath)\n",
    "test_df = test_df.drop(columns=['Sales (Domestic Ultimate Total USD)'])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
